# -*- coding: utf-8 -*-
"""VGG16.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1asDNfPsxuvvhCcUBPGOIVj1zJ6akPFBg
"""

from keras.layers import Input,Lambda, Dense, Flatten
from keras.models import Model
from keras.applications.vgg16 import VGG16, preprocess_input
from keras.preprocessing import image
from keras.preprocessing.image import ImageDataGenerator
import numpy as np
from glob import glob
import matplotlib.pyplot as plt

INPUT_SIZE=[224,224]
train_path='/content/drive/MyDrive/Colab Notebooks/X-Ray/Train'
valid_path='/content/drive/MyDrive/Colab Notebooks/X-Ray/Test'

vgg=VGG16(input_shape=INPUT_SIZE+[3],weights='imagenet',include_top=False)

for layer in vgg.layers:
  layer.trainable=False

folders=glob('/content/drive/MyDrive/Colab Notebooks/X-Ray/Train/*')

x=Flatten()(vgg.output)
x2=Dense(64,activation='relu')(x)
prediction=Dense(len(folders),activation='softmax')(x2)

model=Model(inputs=vgg.input,outputs=prediction)

model.summary()

model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

from keras.preprocessing.image import ImageDataGenerator

train_datagen=ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

test_datagen=ImageDataGenerator(rescale=1./255)

training_set=train_datagen.flow_from_directory(
    train_path,
    target_size=(224,224),
    batch_size=32,
    
    class_mode='categorical',
    shuffle=False
)

from google.colab import drive
drive.mount('/content/drive')

test_set=train_datagen.flow_from_directory(
    valid_path,
    target_size=(224,224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)

vgg_model=model.fit(
    training_set,
    epochs=10,
    validation_data=test_set,
    batch_size=32
)

import pandas as pd

pd.DataFrame(model.history.history).plot()
plt.xlabel('Epoch')

vgg_model=model.fit(
    training_set,
    epochs=10,
    validation_data=test_set,
    batch_size=32
)

pd.DataFrame(model.history.history).plot()
plt.xlabel('Epoch')

vgg_model=model.fit(
    training_set,
    epochs=10,
    validation_data=test_set,
    batch_size=32
)

pd.DataFrame(model.history.history).plot()
plt.xlabel('Epoch')

import tensorflow as tf

vgg_model_2=model.fit(
    training_set,
    epochs=1,
    validation_data=test_set,
    batch_size=32
)

model.save('AIModelVGG2.h5')

import tensorflow as tf
from tensorflow.keras.utils import plot_model

model=tf.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/Model/AIModelVGG2.h5')

plot_model(model,show_shapes=True, show_layer_names=True, rankdir='TB', expand_nested=True)



preds = model.predict(test_set,verbose=1)

predictions = preds.copy()
rounded_labels=np.argmax(preds, axis=1)

import pandas as pd

from sklearn.metrics import classification_report,confusion_matrix
cm = pd.DataFrame(data=confusion_matrix(test_set.classes, rounded_labels, labels=[0, 1, 2]),index=["Pneumonia", "Covid",'Normal'],
columns=["Pneumonia", "Covid",'Normal'])
import seaborn as sns
sns.heatmap(cm,annot=True,fmt="d")

y_true=training_set.classes
rounded_labels=np.argmax(preds, axis=1)

print(classification_report(y_true=test_set.classes,y_pred=rounded_labels,target_names =['Pneumonia','Covid','Normal']))

model.save('VGGModel.h5')

model1=tf.keras.models.load_model('VGGModel.h5')

from tensorflow.keras.models import Model
import tensorflow as tf
import numpy as np
import cv2

class GradCAM:
    def __init__(self, model, classIdx, layerName=None):
        self.model = model
        self.classIdx = classIdx
        self.layerName = layerName
        if self.layerName is None:
            self.layerName = self.find_target_layer()

    def find_target_layer(self):
        for layer in reversed(self.model.layers):
            if len(layer.output_shape) == 4:
                return layer.name
        raise ValueError("Could not find 4D layer. Cannot apply GradCAM.")


    def compute_heatmap(self, image, eps=1e-8):
        gradModel = Model(
            inputs=[self.model.inputs],
            outputs=[self.model.get_layer(self.layerName).output, self.model.output])

        
        with tf.GradientTape() as tape:
            
            inputs = tf.cast(image, tf.float32)
            (convOutputs, predictions) = gradModel(inputs)
            
            loss = predictions[:, tf.argmax(predictions[0])]
    
       
        grads = tape.gradient(loss, convOutputs)

       
        castConvOutputs = tf.cast(convOutputs > 0, "float32")
        castGrads = tf.cast(grads > 0, "float32")
        guidedGrads = castConvOutputs * castGrads * grads
        
        convOutputs = convOutputs[0]
        guidedGrads = guidedGrads[0]

     
        weights = tf.reduce_mean(guidedGrads, axis=(0, 1))
        cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)

        (w, h) = (image.shape[2], image.shape[1])
        heatmap = cv2.resize(cam.numpy(), (w, h))
        
        numer = heatmap - np.min(heatmap)
        denom = (heatmap.max() - heatmap.min()) + eps
        heatmap = numer / denom
        heatmap = (heatmap * 255).astype("uint8")

        return heatmap

    def overlay_heatmap(self, heatmap, image, alpha=0.5,
                        colormap=cv2.COLORMAP_VIRIDIS):
        
        heatmap = cv2.applyColorMap(heatmap, colormap)
        output = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)
        
        return (heatmap, output)

for idx in range(len(model1.layers)):
  print(model.get_layer(index = idx).name)

image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/X-Ray/Test/Bacterial/person100_bacteria_475.jpeg')
image = cv2.resize(image, (224, 224))
image = image.astype('float32') / 255
image = np.expand_dims(image, axis=0)

preds =model1.predict(image) 
i = np.argmax(preds[0])

icam = GradCAM(model1, i, 'block5_conv3') 
heatmap = icam.compute_heatmap(image)
heatmap = cv2.resize(heatmap, (32, 32))

image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/X-Ray/Test/Bacterial/person100_bacteria_475.jpeg')
image = cv2.resize(image, (32, 32))
print(heatmap.shape, image.shape)

(heatmap, output) = icam.overlay_heatmap(heatmap, image, alpha=0.5)

#pneumonia
fig, ax = plt.subplots(1, 3)
ax[0].imshow(heatmap)
ax[1].imshow(image)
ax[2].imshow(output)

#covid
image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/X-Ray/Test/Covid/COVID-3250.png')
image = cv2.resize(image, (224, 224))
image = image.astype('float32') / 255
image = np.expand_dims(image, axis=0)

preds =model1.predict(image) 
i = np.argmax(preds[0])
icam = GradCAM(model1, i, 'block5_conv3') 
heatmap = icam.compute_heatmap(image)
heatmap = cv2.resize(heatmap, (32, 32))

image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/X-Ray/Test/Covid/COVID-3250.png')
image = cv2.resize(image, (32, 32))
print(heatmap.shape, image.shape)

(heatmap, output) = icam.overlay_heatmap(heatmap, image, alpha=0.5)
fig, ax = plt.subplots(1, 3)


ax[0].imshow(heatmap)
ax[1].imshow(image)
ax[2].imshow(output)

image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/X-Ray/Test/Normal/IM-0001-0001.jpeg')
image = cv2.resize(image, (224, 224))
image = image.astype('float32') / 255
image = np.expand_dims(image, axis=0)

preds =model1.predict(image) 
i = np.argmax(preds[0])
icam = GradCAM(model1, i, 'block5_conv3') 
heatmap = icam.compute_heatmap(image)
heatmap = cv2.resize(heatmap, (32, 32))

image = cv2.imread('/content/drive/MyDrive/Colab Notebooks/X-Ray/Test/Normal/IM-0001-0001.jpeg')
image = cv2.resize(image, (32, 32))
print(heatmap.shape, image.shape)

(heatmap, output) = icam.overlay_heatmap(heatmap, image, alpha=0.5)
fig, ax = plt.subplots(1, 3)

ax[0].imshow(heatmap)
ax[1].imshow(image)
ax[2].imshow(output)