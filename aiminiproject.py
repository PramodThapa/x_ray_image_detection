# -*- coding: utf-8 -*-
"""AIMiniProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mz_yUdDGJADjrtkeG-NO1_zhlTQguioH
"""

import matplotlib.pyplot as plt 
import numpy as np             
import pandas as pd             
import tensorflow as tf

IMG_WIDTH=150
IMG_HEIGHT=150

train_image_dir='/content/drive/MyDrive/Colab Notebooks/X-Ray/Train'
validation_dir='/content/drive/MyDrive/Colab Notebooks/X-Ray/Test'
train_sample=120
validation_sample=30
epochs=5
batch_size=20
input_shape=(IMG_WIDTH,IMG_HEIGHT,3)

from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img
train_datagen=ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    width_shift_range=0.2,
    horizontal_flip=True
)

test_datagen=ImageDataGenerator(
    rescale=1./255
)

train_generator=train_datagen.flow_from_directory(
    train_image_dir,
    target_size=(IMG_WIDTH,IMG_HEIGHT),
    su
    batch_size=batch_size,
    class_mode='categorical'
)

validator_gen=test_datagen.flow_from_directory(
    validation_dir,
    target_size=(IMG_HEIGHT,IMG_WIDTH),
    shuffle=True, 
    class_mode='categorical',
    batch_size=20
)

validator_gen

validator_gen.class_indices

plt.figure(figsize=(12, 12))
for i in range(0, 10):
    plt.subplot(2, 5, i+1)
    for X_batch, Y_batch in validator_gen:
        image = X_batch[0] 
        rounded_labels=np.argmax(Y_batch, axis=1)     
        dic = {0:'Pneumonia', 1:'Covid',2:'Normal'}
        plt.title(dic.get(rounded_labels[0]))
        plt.axis('off')
        plt.imshow(np.squeeze(image),cmap='gray',interpolation='nearest')
        break
plt.tight_layout()
plt.show()

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Conv2D,Flatten,MaxPooling2D
from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau

cnn = Sequential()
cnn.add(Conv2D(32, (3, 3), activation="relu", input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)))
cnn.add(MaxPooling2D(pool_size = (2, 2)))

cnn.add(Conv2D(32, (3, 3), activation="relu", input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)))
cnn.add(MaxPooling2D(pool_size = (2, 2)))

cnn.add(Conv2D(32, (3, 3), activation="relu", input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)))
cnn.add(MaxPooling2D(pool_size = (2, 2)))

cnn.add(Conv2D(64, (3, 3), activation="relu", input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)))
cnn.add(MaxPooling2D(pool_size = (2, 2)))

cnn.add(Conv2D(64, (3, 3), activation="relu", input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)))
cnn.add(MaxPooling2D(pool_size = (2, 2)))

cnn.add(Flatten())

cnn.add(Dense(activation = 'relu', units = 128))

cnn.add(Dense(activation = 'relu', units = 64))
cnn.add(Dense(activation = 'softmax', units = 3))

cnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001,beta_1=0.9,beta_2=0.999),
            loss='categorical_crossentropy',
            metrics = ['accuracy'])



from tensorflow.keras.utils import plot_model
plot_model(cnn,show_shapes=True, show_layer_names=True, rankdir='TB', expand_nested=True)

early = EarlyStopping(monitor='val_loss', mode='min', patience=3)
learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)
callbacks_list = [ early, learning_rate_reduction]

from sklearn.utils.class_weight import compute_class_weight
weights = compute_class_weight('balanced', np.unique(train_generator.classes), train_generator.classes)
cw = dict(zip( np.unique(train_generator.classes), weights))
print(cw)

cnn.fit(train_generator,epochs=50, validation_data=validator_gen, class_weight=cw, callbacks=callbacks_list)

#new model
cnn.compile(optimizer=.keras.optimizers.Adam(learning_rate=0.0001,beta_1=0.9,beta_2=0.999),
              loss='categorical_crossentropy',
              metrics=['accuracy']
              )
cnn.fit(train_generator,epochs=50,batch_size=32, validation_data=validator_gen, class_weight=cw)

cnn.save('AIModel1.h5')

pd.DataFrame(cnn.history.history).plot()



from google.colab import drive
drive.mount('/content/drive')

model_path='/content/drive/MyDrive/Colab Notebooks/Model/AIModel1.h5'
cnn=tf.keras.models.load_model(model_path)

test_accu = cnn.evaluate(validator_gen)
print('The testing accuracy is :',test_accu[1]*100, '%')

preds = cnn.predict(validator_gen,verbose=1)

predictions = preds.copy()
rounded_predictions = cnn.predict_classes(validator_gen, batch_size=128, verbose=0)
rounded_predictions

from sklearn.metrics import classification_report,confusion_matrix
cm = pd.DataFrame(data=confusion_matrix(validator_gen.classes, rounded_predictions, labels=[0, 1, 2]),index=["Pneumonia", "Covid",'Normal'],
columns=["Pneumonia", "Covid",'Normal'])
import seaborn as sns
sns.heatmap(cm,annot=True,fmt="d")

y_true=validator_gen.classes
y_true

preds = cnn.predict(validator_gen,verbose=1)
#rounded_labels=np.argmax(test_labels, axis=1)

rounded_labels=np.argmax(preds, axis=1)
rounded_labels

print(classification_report(y_true=validator_gen.classes,y_pred=rounded_labels,target_names =['Pneumonia','Covid','Normal']))

test_image.shape

test_image_pneumonia=load_img('/content/drive/MyDrive/Colab Notebooks/X-Ray/Test/Bacterial/person100_bacteria_475.jpeg',target_size=(150,150))
test_image_pneumonia=img_to_array(test_image_pneumonia)
test_image_pneumonia=np.reshape(test_image_pneumonia,(1,150,150,3))

test_image_pneumonia.shape

layer_outputs = [layer.output for layer in cnn.layers[:15]] # Extracts the outputs of the top 12 layers
activation_model = tf.keras.models.Model(inputs=cnn.input, outputs=layer_outputs) # Creates a model that will return these outputs, given the model input
activations = activation_model.predict(test_image_pneumonia)

cnn.predict_classes(test_image)

first_layer_activation = activations[0]
print(first_layer_activation.shape)

plt.matshow(first_layer_activation[0, :, :, 1], cmap='viridis')

layer_names = []
for layer in cnn.layers[:15]:
    layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot
    
images_per_row = 16
for layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps
    n_features = layer_activation.shape[-1] # Number of features in the feature map
    size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).
    n_cols = n_features // images_per_row # Tiles the activation channels in this matrix
    display_grid = np.zeros((size * n_cols, images_per_row * size))
    for col in range(n_cols): # Tiles each filter into a big horizontal grid
        for row in range(images_per_row):
            channel_image = layer_activation[0,:, :,col * images_per_row + row]
            channel_image -= channel_image.mean() # Post-processes the feature to make it visually palatable
            channel_image /= channel_image.std()
            channel_image *= 64
            channel_image += 128
            channel_image = np.clip(channel_image, 0, 255).astype('uint8')
            display_grid[col * size : (col + 1) * size, # Displays the grid
                         row * size : (row + 1) * size] = channel_image
    scale = 1. / size
    plt.figure(figsize=(scale * display_grid.shape[1],
                        scale * display_grid.shape[0]))
    plt.title(layer_name)
    plt.grid(False)
    plt.imshow(display_grid, aspect='auto', cmap='viridis')

test_image_normal=load_img('/content/drive/MyDrive/Colab Notebooks/X-Ray/Test/Normal/IM-0001-0001.jpeg',target_size=(150,150))
test_image_normal=img_to_array(test_image_normal)
test_image_normal=np.reshape(test_image_normal,(1,150,150,3))

layer_outputs = [layer.output for layer in cnn.layers[:15]] # Extracts the outputs of the top 12 layers
activation_model = tf.keras.models.Model(inputs=cnn.input, outputs=layer_outputs) # Creates a model that will return these outputs, given the model input
activations = activation_model.predict(test_image_normal)
first_layer_activation = activations[0]
print(first_layer_activation.shape)
plt.matshow(first_layer_activation[0, :, :, 1], cmap='viridis')

layer_names = []
for layer in cnn.layers[:15]:
    layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot
    
images_per_row = 16
for layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps
    n_features = layer_activation.shape[-1] # Number of features in the feature map
    size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).
    n_cols = n_features // images_per_row # Tiles the activation channels in this matrix
    display_grid = np.zeros((size * n_cols, images_per_row * size))
    for col in range(n_cols): # Tiles each filter into a big horizontal grid
        for row in range(images_per_row):
            channel_image = layer_activation[0,:, :,col * images_per_row + row]
            channel_image -= channel_image.mean() # Post-processes the feature to make it visually palatable
            channel_image /= channel_image.std()
            channel_image *= 64
            channel_image += 128
            channel_image = np.clip(channel_image, 0, 255).astype('uint8')
            display_grid[col * size : (col + 1) * size, # Displays the grid
                         row * size : (row + 1) * size] = channel_image
    scale = 1. / size
    plt.figure(figsize=(scale * display_grid.shape[1],
                        scale * display_grid.shape[0]))
    plt.title(layer_name)
    plt.grid(False)
    plt.imshow(display_grid, aspect='auto', cmap='viridis')

test_image_covid=load_img('/content/drive/MyDrive/Colab Notebooks/X-Ray/Test/Covid/COVID-3173.png',target_size=(150,150))
test_image_covid=img_to_array(test_image_covid)
test_image_covid=np.reshape(test_image_covid,(1,150,150,3))

layer_outputs = [layer.output for layer in cnn.layers[:15]] # Extracts the outputs of the top 12 layers
activation_model = tf.keras.models.Model(inputs=cnn.input, outputs=layer_outputs) # Creates a model that will return these outputs, given the model input
activations = activation_model.predict(test_image_covid)
first_layer_activation = activations[0]
print(first_layer_activation.shape)
plt.matshow(first_layer_activation[0, :, :, 1], cmap='viridis')

layer_names = []
for layer in cnn.layers[:15]:
    layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot
    
images_per_row = 16
for layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps
    n_features = layer_activation.shape[-1] # Number of features in the feature map
    size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).
    n_cols = n_features // images_per_row # Tiles the activation channels in this matrix
    display_grid = np.zeros((size * n_cols, images_per_row * size))
    for col in range(n_cols): # Tiles each filter into a big horizontal grid
        for row in range(images_per_row):
            channel_image = layer_activation[0,:, :,col * images_per_row + row]
            channel_image -= channel_image.mean() # Post-processes the feature to make it visually palatable
            channel_image /= channel_image.std()
            channel_image *= 64
            channel_image += 128
            channel_image = np.clip(channel_image, 0, 255).astype('uint8')
            display_grid[col * size : (col + 1) * size, # Displays the grid
                         row * size : (row + 1) * size] = channel_image
    scale = 1. / size
    plt.figure(figsize=(scale * display_grid.shape[1],
                        scale * display_grid.shape[0]))
    plt.title(layer_name)
    plt.grid(False)
    plt.imshow(display_grid, aspect='auto', cmap='viridis')